{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4701d36-0f3b-4b4a-a82a-5a435efbe958",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### FUAM deployment script\n",
    "\n",
    "for Release 2025.1.2 and above\n",
    "\n",
    "It works for initial setup and for release updates.\n",
    "\n",
    "\n",
    "##### Before you run this script, please:\n",
    "###### Automatic Deployment Through Github (deploy_from_github = True)\n",
    "1. **Change** the Ids of the connections\n",
    "2. **Run** this notebook\n",
    "3. **Authorize** the connections with Service Principal credentials\n",
    "\n",
    "###### Manual Deployment (deploy_from_github = False)\n",
    "\n",
    "1. **Create** a 'FUAM_Config_Lakehouse'\n",
    "2. **Upload** the **'deployment_file.json'** json file into the **'deployment'** subfolder\n",
    "3. **Change** the Ids of the connections\n",
    "4. **Run** this notebook\n",
    "\n",
    "![FUAM deployment process step 3](https://github.com/GT-Analytics/fuam-basic/blob/main/assets/FUAM_basic_deployment_process_cover_3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5d940-fcbc-467d-969b-4007c8477609",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Attach Lakehouse dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdabf9c-4704-4d3f-a14d-50104959d3cc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    notebookutils.lakehouse.create(name = \"FUAM_Config_Lakehouse\")\n",
    "except Exception as ex:\n",
    "    print('Lakehouse already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d6cbd-ad6e-4fc4-846a-05282c941f34",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "\n",
    "{ \n",
    "        \"defaultLakehouse\": { \n",
    "            \"name\":  \"FUAM_Config_Lakehouse\"\n",
    "            }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533f6fb-396f-422f-b27c-f1d642acbb91",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Connection IDs \n",
    "**Change IDs here ->**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683eee87-ab47-4fc3-b30d-21ff411cd33a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "deploy_from_github = True\n",
    "# target connections (native) - CHANGE HERE\n",
    "pbi_connection_name = 'FUAM-pbi-service-api admin'\n",
    "fabric_connection_name = 'FUAM-fabric-service-api admin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2e6b6-aa02-41e5-b161-35cf1773e8a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Create or Get Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813d3d3-e8da-4048-b453-0440e10b5260",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "# Target workspaceId\n",
    "workspace = spark.conf.get(\"trident.workspace.id\")\n",
    "# Get Access Token\n",
    "pbi_access_token = mssparkutils.credentials.getToken(\"https://analysis.windows.net/powerbi/api\")\n",
    "header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c90a6f-bb98-4765-af72-6d1b9bceb2e3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def create_or_get_connection(name, baseUrl, audience):\n",
    "    # Check if connection has already been created\n",
    "    url = 'https://api.fabric.microsoft.com/v1/connections/'\n",
    "    continuation_token = None\n",
    "    id = None\n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            url_with_token = url + f\"&continuationToken={continuation_token}\"\n",
    "        else:\n",
    "            url_with_token = url\n",
    "\n",
    "        response = requests.get(url=url, headers=header).json()\n",
    "        for row in response['value']:\n",
    "            if row['displayName'] == name:\n",
    "                id = row[\"id\"]\n",
    "                print(\"Connection already exists. Id:\" + id)\n",
    "                return(id)\n",
    "        continuationToken = response.get(\"continuationToken\")\n",
    "        if not continuation_token:\n",
    "            print(f\"I am done for {url}\")\n",
    "            break\n",
    "\n",
    "    # In case there is no connection available yet. Create a new one automatically\n",
    "    conn_json = {\"connectivityType\": \"ShareableCloud\",\n",
    "                \"displayName\": name,\n",
    "                \"connectionDetails\": {\n",
    "                        \"type\": \"WebForPipeline\",\n",
    "                        \"creationMethod\": \"WebForPipeline.Contents\",\n",
    "                        \"parameters\": [{\n",
    "                            \"dataType\": \"Text\",\n",
    "                            \"name\": \"baseUrl\",\n",
    "                            \"value\": baseUrl\n",
    "                            },\n",
    "                            {\n",
    "                            \"dataType\": \"Text\",\n",
    "                            \"name\": \"audience\",\n",
    "                            \"value\": audience\n",
    "                            }\n",
    "                            ]\n",
    "                        },\n",
    "                \"privacyLevel\": \"Organizational\",\n",
    "                \"credentialDetails\": {\n",
    "                    \"singleSignOnType\": \"None\",\n",
    "                    \"connectionEncryption\": \"NotEncrypted\",\n",
    "                    \"skipTestConnection\": False,\n",
    "                    \"credentials\": {\"credentialType\": \"Anonymous\"}\n",
    "                }     \n",
    "            }\n",
    "    url = 'https://api.fabric.microsoft.com/v1/connections/'\n",
    "    response = requests.post(url=url, headers=header, json = conn_json)\n",
    "    print(response.json())\n",
    "    conn_id = response.json()['id']\n",
    "    print(\"Connection created: \" + conn_id + \" . Enter the service principal credentials\")\n",
    "    return(conn_id)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "conn_pbi_service_api_admin = create_or_get_connection(pbi_connection_name, \"https://api.powerbi.com/v1.0/myorg/admin\", \"https://analysis.windows.net/powerbi/api\" )\n",
    "conn_fabric_service_api_admin = create_or_get_connection(fabric_connection_name, \"https://api.fabric.microsoft.com/v1/admin\", \"https://api.fabric.microsoft.com\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6bc03-7fa5-4dae-9bc8-0dd7b1441b4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Deployment logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea473a1-7a57-4a22-a194-2c04fadef7a3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Helper variables\n",
    "fuam_lakehouse_datasets = ['FUAM_Basic_PBI_Overview_SM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12761406-47f5-4f17-87ff-a7072a497dd6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Open deployment json file\n",
    "deployment = {}\n",
    "if deploy_from_github:\n",
    "    print(\"Downloading from Github to FUAM_Config_Lakehouse\")\n",
    "    url = 'https://raw.githubusercontent.com/GT-Analytics/fuam-basic/refs/heads/main/deployment_file.json'\n",
    "    github_download = requests.get(url)\n",
    "    folder_path = mssparkutils.fs.getMountPath('/default') + \"/Files/deployment/\"\n",
    "    mssparkutils.fs.mkdirs(f\"file://\" +folder_path)\n",
    "    with open(folder_path + \"deployment_file.json\", \"w\") as f:\n",
    "        f.write(json.dumps(github_download.json()))\n",
    "    \n",
    "\n",
    "print(\"Read from FUAM_Config_Lakehouse\")\n",
    "with open(mssparkutils.fs.getMountPath('/default') + \"/Files/deployment/deployment_file.json\") as f:\n",
    "        deployment = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984f68b-e3f2-4bc5-88eb-3f0ae72c2126",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Prepare JSON for deployment\n",
    "guids_to_replace = [{ \"old_id\" : deployment[\"old_workspace\"] , \"new_id\" : workspace}]\n",
    "guids_to_replace.append({ \"old_id\" : deployment[\"connections\"][\"conn_pbi_service_api_admin_old\"] , \"new_id\" : conn_pbi_service_api_admin})\n",
    "guids_to_replace.append({ \"old_id\" : deployment[\"connections\"][\"conn_fabric_service_api_admin_old\"] , \"new_id\" : conn_fabric_service_api_admin})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e1f3c-2169-4620-91b0-9d1216d7baa0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get existing items\n",
    "# (relevant for FUAM release update)\n",
    "url = 'https://api.fabric.microsoft.com/v1/workspaces/'+ workspace +'/items/'\n",
    "existing_items = requests.get(url=url, headers=header).json()[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2494b7-b9dc-4b3a-8671-527b618bf333",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Function to get ids from existing items\n",
    "# (relevant for FUAM release update)\n",
    "def id_for_existing_items ( name , type):\n",
    "    for it in existing_items:\n",
    "        if name == it[\"displayName\"] and type == it[\"type\"]:\n",
    "            return it[\"id\"]\n",
    "    return \"New Item\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829026fd-13a5-4684-b926-35878b0b5d3a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "guids_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36800b-20a9-48d0-9203-f4a38742968a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "items_to_deploy = deployment[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627f710-46de-436e-951f-58d0335bc946",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if existing items\n",
    "# (relevant for FUAM release update)\n",
    "def check_if_item_exists(old_id):\n",
    "    for row in guids_to_replace:\n",
    "        if old_id == row['old_id']:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba584a7-5e8f-49c5-8ef4-e865a988236e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Deploy items one by one to workspace\n",
    "# if item new, then create it\n",
    "# if exists already, then update it\n",
    "for item in items_to_deploy:\n",
    "    rename_item = {}\n",
    "    rename_item[\"old_id\"] = item[\"org_id\"]\n",
    "\n",
    "    print('Deploy ' + item['displayName'] )  \n",
    "\n",
    "    if 'definition' in item.keys():\n",
    "        b = item['definition']['parts'][0]['payload']\n",
    "        decoded = base64.b64decode(b).decode('utf-8')\n",
    "\n",
    "        for repl in guids_to_replace:\n",
    "            decoded = decoded.replace(repl[\"old_id\"], repl[\"new_id\"])\n",
    "        encoded = base64.b64encode(decoded.encode('utf-8'))\n",
    "        item['definition']['parts'][0]['payload'] = encoded\n",
    "\n",
    "    it = item\n",
    "    header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "\n",
    "    existing_id = id_for_existing_items(item['displayName'], item['type'])\n",
    "    if existing_id == \"New Item\":\n",
    "        print( \"Create \")\n",
    "        url = 'https://api.fabric.microsoft.com/v1/workspaces/'+ workspace + '/items/'\n",
    "        response = requests.post(url=url, headers=header, json = item)\n",
    "    else:\n",
    "        print( \"Update \")\n",
    "        url = 'https://api.fabric.microsoft.com/v1/workspaces/'+ workspace + '/items/' + existing_id + \"/updateDefinition\"\n",
    "        response = requests.post(url=url, headers=header, json = item) \n",
    "\n",
    "    if response.status_code == 202:\n",
    "        get_op = 'Running'\n",
    "        while get_op != 'Succeeded' and get_op != 'Failed':\n",
    "            time.sleep(1.5)\n",
    "                \n",
    "            header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "            response2 = requests.get(url=response.headers[\"location\"], headers=header)\n",
    "            get_op = response2.json()['status']\n",
    "            print(get_op)\n",
    "\n",
    "            header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "\n",
    "            response3 = requests.get(url=response.headers[\"location\"]+ \"/result\", headers=header)\n",
    "            response3 = response3.json()\n",
    "    else:\n",
    "        if existing_id == \"New Item\":\n",
    "            response3 = response.json()\n",
    "    if existing_id == \"New Item\":\n",
    "        rename_item[\"new_id\"] = response3[\"id\"]\n",
    "    else:\n",
    "        rename_item[\"new_id\"] = existing_id\n",
    "    guids_to_replace.append(rename_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e5e9b-a2ef-4755-abf7-396196a12c93",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get existing items after deployment\n",
    "header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "url = 'https://api.fabric.microsoft.com/v1/workspaces/'+ workspace +'/items/'\n",
    "existing_items = requests.get(url=url, headers=header).json()[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d0c10-6db0-431b-9bbe-dbfb2bb47146",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get SQL Endpoint properties for main Lakehouse\n",
    "header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "url = 'https://api.fabric.microsoft.com/v1/workspaces/'+ workspace +'/lakehouses/' + id_for_existing_items('FUAM_Lakehouse', 'Lakehouse')\n",
    "response = requests.get(url=url, headers=header)\n",
    "new_sqlEndPointProperties = response.json()['properties']['sqlEndpointProperties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b5f5d-2d3b-4f39-97e0-ad76d9b83b1b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "new_sqlEndPointProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c7ba6-40ee-4c75-9664-05a69669fcec",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set SQL Endpoint\n",
    "old_sql_EndPointProperties = deployment['sqlEndPointProperties']\n",
    "old_sql_EndPointProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8c43a-6e75-45ed-a423-1b0a4b443481",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "update_datasource_json = {}\n",
    "updateDetails = []\n",
    "single_updateDetails = {}\n",
    "single_updateDetails['datasourceSelector'] = {}\n",
    "single_updateDetails['datasourceSelector']['datasourceType'] = \"Sql\"\n",
    "single_updateDetails['datasourceSelector'][\"connectionDetails\"] = {}\n",
    "single_updateDetails['datasourceSelector'][\"connectionDetails\"][\"server\"] = old_sql_EndPointProperties['connectionString']\n",
    "single_updateDetails['datasourceSelector'][\"connectionDetails\"][\"database\"] = old_sql_EndPointProperties['id']\n",
    "\n",
    "single_updateDetails['connectionDetails'] = {}\n",
    "single_updateDetails['connectionDetails'][\"server\"] = new_sqlEndPointProperties['connectionString']\n",
    "single_updateDetails['connectionDetails'][\"database\"] = new_sqlEndPointProperties['id']\n",
    "\n",
    "updateDetails.append(single_updateDetails)\n",
    "update_datasource_json['updateDetails'] = updateDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cfafd-242b-4a12-a4c6-906c495d6d0f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "update_datasource_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3483c-a796-4f40-849a-903bcb3c208e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Update connection between semantic model and lakehouse\n",
    "for sm in fuam_lakehouse_datasets:\n",
    "    print(sm)\n",
    "\n",
    "    max_tries = 0\n",
    "    status_code = 0\n",
    "    while (status_code != 200) & (max_tries < 3):\n",
    "    \n",
    "        header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "        url = 'https://api.powerbi.com/v1.0/myorg/datasets/'+  id_for_existing_items(sm, 'SemanticModel') + '/Default.UpdateDatasources' \n",
    "        response = requests.post(url=url, headers=header, json = update_datasource_json)\n",
    "        print(response.status_code)\n",
    "                      \n",
    "        print(f\"Status code for semantic model {sm}:\" +  str(response.status_code))\n",
    "        max_tries = max_tries + 1 \n",
    "        status_code = response.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a363f-9983-4148-a412-858ed0724517",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Import table definitions and create tables in FUAM_Lakehouse\n",
    "existing_tables = [table['name'] for table in notebookutils.lakehouse.listTables(\"FUAM_Lakehouse\")]\n",
    "for table_definition in deployment[\"table_definitions\"]:\n",
    "    if not(table_definition['table'] in existing_tables):\n",
    "        print(\"Create table \" + table_definition['table'])\n",
    "        spark.sql(table_definition['create_sql'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9cfada-3673-4112-8f83-957d310e4f37",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Refresh datasets\n",
    "for sm in fuam_lakehouse_datasets:\n",
    "    print(sm)\n",
    "    refresh_json = {}\n",
    "    refresh_json[\"notifyOption\"] = \"NoNotification\"\n",
    "    refresh_json[\"retryCount\"] = \"3\"\n",
    "    header = {'Content-Type':'application/json','Authorization': f'Bearer {pbi_access_token}'}\n",
    "    url = 'https://api.powerbi.com/v1.0/myorg/datasets/'+  id_for_existing_items(sm, 'SemanticModel') + '/refreshes' \n",
    "    response = requests.post(url=url, headers=header, json = refresh_json)\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62f436-cdaa-4314-82ea-045f6f44a9e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "##### Post-Deployment logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf7b03-dea6-4910-b960-5f7acfcc442e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "\n",
    "{ \n",
    "    \"defaultLakehouse\": { \n",
    "        \"name\":  \"FUAM_Lakehouse\"\n",
    "           }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f270a-d2ad-4b42-8621-825b852e32de",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, sequence\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb762b-ff9d-4666-8b93-2b5882e896d0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Define the data as a dictionary\n",
    "capacity_regions = pd.DataFrame(\n",
    "    [\n",
    "    (\"Asia Pacific\", \"Australia East\", 31.2532, 146.9211, \"New South Wales\"),\n",
    "    (\"Asia Pacific\", \"Australia Southeast\", 36.9848, 143.3906, \"Victoria\"),\n",
    "    (\"Asia Pacific\", \"Central India\", 18.5204, 73.8567, \"Pune\"),\n",
    "    (\"Asia Pacific\", \"East Asia\", 22.3193, 114.1694, \"Hong Kong\"),\n",
    "    (\"Asia Pacific\", \"Japan East\", 35.6764, 139.65, \"Tokyo\"),\n",
    "    (\"Asia Pacific\", \"Korea Central\", 37.5519, 126.9918, \"Seoul\"),\n",
    "    (\"Asia Pacific\", \"Southeast Asia\", 1.3521, 103.8198, \"Singapore\"),\n",
    "    (\"Asia Pacific\", \"South India\", 13.0827, 80.2707, \"Chennai\"),\n",
    "    (\"Europe\", \"North Europe\", 53.7798, 7.3055, \"Ireland\"),\n",
    "    (\"Europe\", \"West Europe\", 52.1326, 5.2913, \"Netherlands\"),\n",
    "    (\"Europe\", \"France Central\", 48.8566, 2.3522, \"Paris\"),\n",
    "    (\"Europe\", \"Germany West Central\", 50.1109, 8.6821, \"Frankfurt am Main\"),\n",
    "    (\"Europe\", \"Norway East\", 59.9139, 10.7522, \"Oslo\"),\n",
    "    (\"Europe\", \"Sweden Central\", 60.6749, 17.1413, \"Gävle\"),\n",
    "    (\"Europe\", \"Switzerland North\", 47.3769, 8.5417, \"Zürich\"),\n",
    "    (\"Europe\", \"Switzerland West\", 46.2044, 6.1432, \"Geneva\"),\n",
    "    (\"Europe\", \"UK South\", 51.5072, -0.1276, \"London\"),\n",
    "    (\"Europe\", \"UK West\", 51.4837, -3.1681, \"Cardiff\"),\n",
    "    (\"Americas\", \"Brazil South\", -23.5558, -46.6396, \"São Paulo State\"),\n",
    "    (\"Americas\", \"Canada Central\", 43.6532, -79.3832, \"Toronto\"),\n",
    "    (\"Americas\", \"Canada East\", 46.8131, -71.2075, \"Quebec City\"),\n",
    "    (\"Americas\", \"East US\", 37.4316, -78.6569, \"Virginia\"),\n",
    "    (\"Americas\", \"East US 2\", 37.4316, -78.6569, \"Virginia\"),\n",
    "    (\"Americas\", \"North Central US\", 40.6331, -89.3985, \"Illinois\"),\n",
    "    (\"Americas\", \"South Central US\", 31.9686, -99.9018, \"Texas\"),\n",
    "    (\"Americas\", \"West US\", 36.7783, -119.4179, \"California\"),\n",
    "    (\"Americas\", \"West US 2\", 47.7511, -120.7401, \"Washington\"),\n",
    "    (\"Americas\", \"West US 3\", 34.0489, -111.0937, \"Arizona\"),\n",
    "    (\"Middle East and Africa\", \"South Africa North\", -26.2056, 28.0337, \"Johannesburg\"),\n",
    "    (\"Middle East and Africa\", \"UAE North\", 25.2048, 55.2708, \"Dubai\")\n",
    "],\n",
    "    columns=[\n",
    "        \"Continent\",\n",
    "        \"FabricRegion\",\n",
    "        \"Latitude\",\n",
    "        \"Longitude\",\t\n",
    "        \"Location\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a DataFrame\n",
    "capacity_regions_df = pd.DataFrame(capacity_regions)\n",
    "\n",
    "# Write Capacity regions to Lakehouse table\n",
    "fc_convert_dict = {'Continent': str, 'FabricRegion': str, 'Latitude': str, 'Longitude': str, 'Location': str}\n",
    "rules_catalog_df = capacity_regions_df.astype(fc_convert_dict)\n",
    "fc_spark_df = spark.createDataFrame(capacity_regions_df)\n",
    "\n",
    "fc_spark_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(\"capacity_regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a944a4-2e18-4b4c-a6af-897b3ff26bb2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
